{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "packed-equivalent",
   "metadata": {},
   "source": [
    "# Documents-Term Matrix(DTM)\n",
    "\n",
    "    서로 다른 문서들의 BoW들을 결합한 표현 방법.\n",
    "    \n",
    "    한계 :\n",
    "        1) 희소 표현\n",
    "           -> 단어 집합의 크기를 줄이는 일이 중요하다.\n",
    "        2) 단순 빈도 수 기반 접근\n",
    "           -> the 같은 불용어가 자주 등장 할 수 밖에 없다.\n",
    "           -> 중요한 단어에 가중치를 주는 방법(TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "anonymous-train",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 1 0 1 0 1 1]\n",
      " [0 0 1 0 0 0 0 1 0]\n",
      " [1 0 0 0 1 0 1 0 0]]\n",
      "{'you': 7, 'know': 1, 'want': 5, 'your': 8, 'love': 3, 'like': 2, 'what': 6, 'should': 4, 'do': 0}\n"
     ]
    }
   ],
   "source": [
    "# DTM 구현\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "corpus = [\n",
    "    'you know I want your love',\n",
    "    'I like you',\n",
    "    'what should I do ',    \n",
    "]\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "DTM = vectorizer.fit_transform(corpus)\n",
    "\n",
    "print(DTM.toarray())\n",
    "print(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "configured-albert",
   "metadata": {},
   "source": [
    "# Term Frequency-Inverse Document Frequency(TF-IDF)\n",
    "\n",
    "    각 단어에 대한 중요도 계산할 수 있는 가중치.\n",
    "    기존의 DTM 보다 더 많은 정보를 고려하여 문서 비교 가능(but, 항상 성능이 뛰어난건 아니다.)\n",
    "    \n",
    "    문서 : d / 단어 : t / 문서 총 개수 : n\n",
    "    TF(d,t) : 특정 문서 d에서의 특정 단어 t의 등장 횟수 (BoW)\n",
    "    DF(t)   : 특정 단어 t가 등장한 문서의 수\n",
    "              (몇번 등장했는 지는 중요하지 않고, 문서의 수만 생각)\n",
    "    IDF(d,t): DF(t)에 반비례하는 수\n",
    "              IDF(d,t) = log(n / 1 + DF(t))\n",
    "              \n",
    "              1) log 취한 이유 : n이 커질 수록 IDF값이 기하급수로 커지기 때문에 가중치 격차 줄이기 위함.\n",
    "              2) 분모에 1 더해주는 이유 : DF(t) 가 0일 경우에 분모가 0이 됨으로.\n",
    "    => 모든 문서에 자주 등장하는 단어는 중요도가 낮고, 특정 문서에만 자주 등장하는 단어는 중요도가 높게 판단.\n",
    "    => TF-IDF 값이 낮으면 중요도가 낮고, 높으면 중요도가 높다.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annual-pixel",
   "metadata": {},
   "source": [
    "#### sklearn 으로 구현\n",
    "    \n",
    "    차이 : \n",
    "        1) IDF를 IDF(d,t) = log(n / 1 + DF(t)) + 1 로 구현. \n",
    "            -> log 값이 0이 되는 경우 고려.\n",
    "        2) TF-IDF에 L2 정규화 로 값을 조정.\n",
    "        등등.\n",
    "    \n",
    "    그냥 사용해도 된다.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "imposed-horse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.46735098 0.         0.46735098 0.         0.46735098\n",
      "  0.         0.35543247 0.46735098]\n",
      " [0.         0.         0.79596054 0.         0.         0.\n",
      "  0.         0.60534851 0.        ]\n",
      " [0.57735027 0.         0.         0.         0.57735027 0.\n",
      "  0.57735027 0.         0.        ]]\n",
      "{'you': 7, 'know': 1, 'want': 5, 'your': 8, 'love': 3, 'like': 2, 'what': 6, 'should': 4, 'do': 0}\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF 구현\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "corpus = [\n",
    "    'you know I want your love',\n",
    "    'I like you',\n",
    "    'what should I do ',    \n",
    "]\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf = vectorizer.fit_transform(corpus)\n",
    "\n",
    "print(tfidf.toarray())\n",
    "print(vectorizer.vocabulary_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
